{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2202646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T12:11:00.426612Z",
     "start_time": "2022-03-10T12:11:00.418650Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import hyperopt as hp\n",
    "from numpy.random import RandomState\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "config = {\n",
    "\"font.family\": 'serif', # 衬线字体\n",
    "\"font.serif\": ['SimSun'], # 宋体\n",
    "\"mathtext.fontset\": 'stix', # matplotlib渲染数学字体时使用的字体，和Times New Roman差别不大\n",
    "'axes.unicode_minus': False # 处理负号，即-号\n",
    "}\n",
    "rcParams.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a783e047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:26:52.629799Z",
     "start_time": "2022-03-10T08:26:52.602274Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(filepath_or_buffer=\"../../Desktop/data/train1.csv\",encoding=\"gbk\")\n",
    "train = pd.DataFrame(train)\n",
    "#test = pd.read_csv(filepath_or_buffer=\"../../Desktop/recent/ImmuneTest.csv\")\n",
    "#test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14cc5e50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:27:20.125789Z",
     "start_time": "2022-03-10T08:27:20.089787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['安徽.蚌埠', '安徽.合肥', '福建.福州', '福建.泉州', '广东.潮州', '广东.深圳', '河南.三门峡',\n",
       "       '黑龙江.绥化', '湖北.武汉', '湖南.长沙', '江苏.连云港', '辽宁.大连', '山东.临沂', '陕西.西安',\n",
       "       '上海.上海', '四川.成都', '香港.未知', '重庆.重庆', '日期', '是否是周末', '小时', '分钟', '秒',\n",
       "       '所用时间', '来源', 'Q1.您的年龄', 'Q2.您的性别', 'Q3.A.完全不了解.', 'Q3.B.略有耳闻.',\n",
       "       'Q3.C.一般了解.', 'Q3.D.非常了解.', 'Q4.A.传播速度快.', 'Q4.B.时效性强.', 'Q4.C.信息容量大.',\n",
       "       'Q4.D.信息覆盖范围广.', 'Q4.E.高度开放性.', 'Q4.F.具有民族性和地域性.', 'Q4.G.跨地域性.',\n",
       "       'Q5.您对.目前互联网文化是以青年为主的文化.的观点的认同程度..1.5打分.',\n",
       "       'Q6.您对.高质量发展青年互联网文化.是其成为文化强国有机组成部分.的认同程度.',\n",
       "       'Q7.您对.目前互联网文化仍需加强监管.的观点的认同程度..1.5打分.', 'Q8.您认为最有效的监管措施是.',\n",
       "       'Q9.您主要的上网途径是.', 'Q10.A.学习.查资料.', 'Q10.B.刷视频.看剧.听音乐.', 'Q10.C.社交.',\n",
       "       'Q10.D.玩游戏.', 'Q10.E.网购.', 'Q10.F.手机支付.', 'Q10.G.看小说.', 'Q10.H.炒股等理财.'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "caa641cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T12:23:49.335445Z",
     "start_time": "2022-03-10T12:23:49.119741Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92\n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 2.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttrain's rmse: 0.416294\tvalid's rmse: 0.748124\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\ttrain's rmse: 0.326984\tvalid's rmse: 0.702226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\ttrain's rmse: 0.230573\tvalid's rmse: 0.675836\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttrain's rmse: 0.162913\tvalid's rmse: 0.671785\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[383]\ttrain's rmse: 0.172782\tvalid's rmse: 0.671607\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 96\n",
      "[LightGBM] [Info] Number of data points in the train set: 15, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 1.800000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's rmse: 0.650301\tvalid's rmse: 0.664314\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 15, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 2.066667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttrain's rmse: 0.634459\tvalid's rmse: 0.545492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "ESR = 30\n",
    "NBR = 10000\n",
    "VBE = 100\n",
    "evals_result = {}  # 记录训练结果所用\n",
    "params = params_append(params)\n",
    "kf = sk.model_selection.KFold(n_splits=3,\n",
    "                              #random_state=2020,\n",
    "                              shuffle=True)\n",
    "label = [f for f in train.columns if f in ['Q6.您对.高质量发展青年互联网文化.是其成为文化强国有机组成部分.的认同程度.']]\n",
    "features = [f for f in train.columns if f not in [ '小时', '分钟', '秒','Q6.您对.高质量发展青年互联网文化.是其成为文化强国有机组成部分.的认同程度.']]\n",
    "for train_part_index,eval_index in kf.split(train[features],train[label]):\n",
    "        eval = lgb.Dataset(train[features].loc[eval_index],train[label].loc[eval_index])\n",
    "        train_part = lgb.Dataset(train[features].loc[train_part_index],train[label].loc[train_part_index])\n",
    "        bst = lgb.train(params,train_part,num_boost_round=NBR,valid_sets=[train_part,eval],evals_result=evals_result,\n",
    "                valid_names=['train','valid'],early_stopping_rounds=ESR,verbose_eval=VBE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26462a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(10,8),dpi=150)\n",
    "ax = lgb.plot_metric(evals_result, metric='rmse')  # metric的值与之前的params里面的值对应\n",
    "plt.savefig(\"您对.高质量发展青年互联网文化.是其成为文化强国有机组成部分.的认同程度.jpg\", format=\"jpg\",bbox_inches = 'tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f89195f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T12:23:55.677765Z",
     "start_time": "2022-03-10T12:23:55.192073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.rc(\"font\",family='FangSong')\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "lgb.plot_importance(bst, max_num_features=10, ax=ax)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel('Feature importance',fontsize=14)\n",
    "plt.ylabel('Features',fontsize=14)\n",
    "plt.savefig(\"feature_importance_Q6.jpg\", format=\"jpg\",bbox_inches = 'tight', dpi=500)\n",
    "\n",
    "\n",
    "importance = bst.feature_importance(importance_type='split')\n",
    "feature_name = bst.feature_name()\n",
    "# for (feature_name,importance) in zip(feature_name,importance):\n",
    "#     print (feature_name,importance) \n",
    "feature_importance = pd.DataFrame({\n",
    "  'feature_name':feature_name,'importance':importance} )\n",
    "feature_importance.to_csv('feature_importance_Q6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f9b655e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Step 1 ======\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18\n",
      "[LightGBM] [Info] Number of data points in the train set: 5, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 107.431920\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's rmse: 0.130082\tvalid_1's rmse: 0.201302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\ttraining's rmse: 0.130082\tvalid_1's rmse: 0.201302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\ttraining's rmse: 0.130082\tvalid_1's rmse: 0.201302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's rmse: 0.130082\tvalid_1's rmse: 0.201302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[500]\ttraining's rmse: 0.130082\tvalid_1's rmse: 0.201302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "MAX_ROUNDS = 500\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "label = [f for f in train.columns if f in ['户籍人口']]\n",
    "features = [f for f in train.columns if f not in ['户籍人口']]\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    print(\"====== Step %d ======\" % (i+1))\n",
    "    \n",
    "    trainFeature = train[i:(i+5)]\n",
    "    X_train = trainFeature\n",
    "    y_train = train[(i+5):(i+10)][label]\n",
    "\n",
    "\n",
    "    valFeature = train[(i+9):(i+10)]\n",
    "    X_val = valFeature\n",
    "    y_val = train[(i+9):(i+10)][label]\n",
    "    \n",
    "    testFeature = train[(i+10):(i+11)]\n",
    "    X_test = testFeature\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dval = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    bst = lgb.train(\n",
    "            params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "            valid_sets=[dtrain, dval], \n",
    "            verbose_eval=100)\n",
    "    \n",
    "    val_pred.append(bst.predict(X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_p = bst.predict(X_test)\n",
    "    #df_train = np.append(train,test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1814f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106.91870118])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aadf2b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:28:10.140267Z",
     "start_time": "2022-03-10T08:28:10.129282Z"
    }
   },
   "outputs": [],
   "source": [
    "def  params_append(params):\n",
    "    params['objective'] = 'regression',\n",
    "    params['metric'] = 'rmse',\n",
    "    params['feature_pre_filter']=False\n",
    "    #params['num_class']=6\n",
    "    #params['is_unbalance']=True\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0dc6bd75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:30:30.216666Z",
     "start_time": "2022-03-10T08:30:30.207668Z"
    }
   },
   "outputs": [],
   "source": [
    "def param_hyperopt(train):\n",
    "    label = [f for f in train.columns if f in ['Q6.您对.高质量发展青年互联网文化.是其成为文化强国有机组成部分.的认同程度.']]\n",
    "    features = [f for f in train.columns if f not in ['小时', '分钟', '秒','Q6.您对.高质量发展青年互联网文化.是其成为文化强国有机组成部分.的认同程度.']]\n",
    "    train_data = lgb.Dataset(train[features],train[label],silent=True)\n",
    "    def hyperopt_objective(params):\n",
    "        params = params_append(params)\n",
    "        print(params)\n",
    "        res = lgb.cv(params,train_data,10000,nfold=3,stratified=False,shuffle=True,metrics='rmse',\n",
    "                     early_stopping_rounds=30,\n",
    "                     verbose_eval=False,show_stdv=False)\n",
    "        return min(res['rmse-mean'])\n",
    "        #return (1-max(res['multi_error-mean']))\n",
    "    #参数空间\n",
    "    \n",
    "    params_space = {\n",
    "        'learning_rate': hp.hp.uniform('learning_rate',1e-5,1e-2),\n",
    "        'bagging_fraction': hp.hp.uniform('bagging_fraction',0.5,1),\n",
    "        'feature_fraction': hp.hp.uniform('feature_fraction',0.5,1),\n",
    "        'num_leaves': hp.hp.choice('num_leaves',list(range(2,50,2))),\n",
    "        'reg_alpha': hp.hp.randint('reg_alpha',0,10),\n",
    "        'reg_lambda': hp.hp.uniform('reg_lambda',0,10),\n",
    "        'bagging_freq': hp.hp.randint('bagging_freq',1,10),\n",
    "        'min_child_samples': hp.hp.choice('min_child_samples',list(range(2,30,2))),\n",
    "        #'scale_pos_weight' : hp.hp.uniform('scale_pos_weight',1,20),\n",
    "        'device' : 'gpu',\n",
    "        'gpu_platform_id':1,\n",
    "        'gpu_device_id':1\n",
    "        \n",
    "    }\n",
    "    params_best = hp.fmin(\n",
    "        hyperopt_objective,\n",
    "        space=params_space,\n",
    "        algo=hp.tpe.suggest,\n",
    "        max_evals=100,\n",
    "#         rstate=RandomState(2020)\n",
    "    )\n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "395370cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:35:53.515620Z",
     "start_time": "2022-03-10T08:30:31.496669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.9686395407870263, 'bagging_freq': 6, 'device': 'gpu', 'feature_fraction': 0.5702117066739054, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007458203181474936, 'min_child_samples': 26, 'num_leaves': 30, 'reg_alpha': 0, 'reg_lambda': 4.61256620838483, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001612 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\basic.py:1491: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via 'params' instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001629 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001825 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8231756744603201, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.7670767936163432, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0031242158420314026, 'min_child_samples': 14, 'num_leaves': 24, 'reg_alpha': 6, 'reg_lambda': 6.581506191579292, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "  1%|▍                                               | 1/100 [00:00<00:47,  2.11trial/s, best loss: 2.0369492111539595]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002597 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001779 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.003970 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.68195400705398, 'bagging_freq': 9, 'device': 'gpu', 'feature_fraction': 0.6024640299959805, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004317118518039044, 'min_child_samples': 14, 'num_leaves': 6, 'reg_alpha': 8, 'reg_lambda': 3.587643549002143, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001528 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001473 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7237789664888302, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9912879257315222, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.002246109792532072, 'min_child_samples': 4, 'num_leaves': 6, 'reg_alpha': 1, 'reg_lambda': 9.05446011876871, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001547 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001472 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001920 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7965775525158205, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.6565673363193258, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009528013023101311, 'min_child_samples': 26, 'num_leaves': 6, 'reg_alpha': 2, 'reg_lambda': 4.743214508170938, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002274 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.003462 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002431 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6133434353062615, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.6623117394403735, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.002494294416683823, 'min_child_samples': 24, 'num_leaves': 2, 'reg_alpha': 1, 'reg_lambda': 2.877236825348868, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001546 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001334 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002183 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6304994411318094, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.6633667146221978, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008984955200224383, 'min_child_samples': 20, 'num_leaves': 38, 'reg_alpha': 2, 'reg_lambda': 3.3904290685770935, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001285 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001434 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001915 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.5867077237698681, 'bagging_freq': 1, 'device': 'gpu', 'feature_fraction': 0.540169523831429, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008926502588868254, 'min_child_samples': 2, 'num_leaves': 24, 'reg_alpha': 8, 'reg_lambda': 1.435242928884275, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001741 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001425 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8898084637712359, 'bagging_freq': 2, 'device': 'gpu', 'feature_fraction': 0.726771432971054, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005163151514586249, 'min_child_samples': 28, 'num_leaves': 46, 'reg_alpha': 4, 'reg_lambda': 9.317156201201325, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001975 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001577 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8661108672281217, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.7513213239173697, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008968069281380844, 'min_child_samples': 20, 'num_leaves': 24, 'reg_alpha': 9, 'reg_lambda': 9.873508499851534, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001981 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.008856 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002064 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.69184266687106, 'bagging_freq': 4, 'device': 'gpu', 'feature_fraction': 0.6038197378847687, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007127978975117499, 'min_child_samples': 2, 'num_leaves': 26, 'reg_alpha': 9, 'reg_lambda': 1.3153866558137328, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001480 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001553 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001440 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6945264916131231, 'bagging_freq': 2, 'device': 'gpu', 'feature_fraction': 0.6957750772017475, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004412727796164437, 'min_child_samples': 28, 'num_leaves': 44, 'reg_alpha': 6, 'reg_lambda': 9.569759821917076, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001552 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001756 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.003372 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6435234331632899, 'bagging_freq': 4, 'device': 'gpu', 'feature_fraction': 0.6317793925574697, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0030055535107197024, 'min_child_samples': 12, 'num_leaves': 12, 'reg_alpha': 9, 'reg_lambda': 2.8960179920687446, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001524 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001544 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.005073 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7469599538471041, 'bagging_freq': 4, 'device': 'gpu', 'feature_fraction': 0.7131910189920929, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0015611029391598716, 'min_child_samples': 4, 'num_leaves': 18, 'reg_alpha': 9, 'reg_lambda': 4.8550148967120474, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001471 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001746 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.638015875421127, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.691468577725735, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0052047385053998075, 'min_child_samples': 8, 'num_leaves': 16, 'reg_alpha': 8, 'reg_lambda': 8.201563667860537, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001414 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001619 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001705 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8929212096010724, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.5892623825616414, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006880262756139525, 'min_child_samples': 10, 'num_leaves': 20, 'reg_alpha': 3, 'reg_lambda': 2.7073392938967897, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001370 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001683 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002872 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7242661747373716, 'bagging_freq': 9, 'device': 'gpu', 'feature_fraction': 0.8735862544885034, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0032352953645713735, 'min_child_samples': 18, 'num_leaves': 18, 'reg_alpha': 2, 'reg_lambda': 2.0035426109814236, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001910 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001728 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001734 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.5859039802835326, 'bagging_freq': 9, 'device': 'gpu', 'feature_fraction': 0.9486959870982798, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.00033261866889395804, 'min_child_samples': 14, 'num_leaves': 26, 'reg_alpha': 0, 'reg_lambda': 3.2518396184631104, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001815 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001410 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001532 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.67493874451489, 'bagging_freq': 6, 'device': 'gpu', 'feature_fraction': 0.7665173036683794, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007360467896286155, 'min_child_samples': 12, 'num_leaves': 48, 'reg_alpha': 4, 'reg_lambda': 0.25780352328525935, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001493 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001739 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001943 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.984237514389783, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.8184281565525979, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004575118683381195, 'min_child_samples': 26, 'num_leaves': 40, 'reg_alpha': 4, 'reg_lambda': 9.504491649764194, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001394 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001710 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001497 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.5041330098706928, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9991377091392543, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 2.6644795278652975e-05, 'min_child_samples': 6, 'num_leaves': 30, 'reg_alpha': 1, 'reg_lambda': 6.449354053819374, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001740 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001825 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001706 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9452474808163681, 'bagging_freq': 6, 'device': 'gpu', 'feature_fraction': 0.5025373806010747, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006506008547066906, 'min_child_samples': 16, 'num_leaves': 28, 'reg_alpha': 7, 'reg_lambda': 6.480302869983094, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001327 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001726 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001892 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8015417719379457, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9449721910801865, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0013720037036682523, 'min_child_samples': 22, 'num_leaves': 36, 'reg_alpha': 0, 'reg_lambda': 7.814440729073933, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002093 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001597 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001732 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9590709729211201, 'bagging_freq': 6, 'device': 'gpu', 'feature_fraction': 0.8406873925156845, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007925571068618029, 'min_child_samples': 4, 'num_leaves': 32, 'reg_alpha': 5, 'reg_lambda': 5.33865562060608, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002176 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001672 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001931 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7562710668089371, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.5016452649303704, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005889302816650019, 'min_child_samples': 4, 'num_leaves': 30, 'reg_alpha': 0, 'reg_lambda': 7.832690968105311, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001714 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001347 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001499 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7694083255775417, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9996746361976618, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005810356387955282, 'min_child_samples': 4, 'num_leaves': 10, 'reg_alpha': 1, 'reg_lambda': 8.647209745193218, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001760 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001959 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001626 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8436622960373943, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8915984342656488, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006084580113316805, 'min_child_samples': 4, 'num_leaves': 10, 'reg_alpha': 0, 'reg_lambda': 8.156721894602418, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001789 secs. 1 sparse feature groups       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001781 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001353 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8412808611177535, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9236817844715336, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0059379103943371925, 'min_child_samples': 4, 'num_leaves': 4, 'reg_alpha': 0, 'reg_lambda': 7.425518576153461, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001548 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001726 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001834 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8522636473592137, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8941586198301128, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.00830232682887673, 'min_child_samples': 4, 'num_leaves': 4, 'reg_alpha': 0, 'reg_lambda': 7.273234848053435, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001667 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001667 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001728 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8781235529100634, 'bagging_freq': 1, 'device': 'gpu', 'feature_fraction': 0.8882400285362877, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008081936614157403, 'min_child_samples': 10, 'num_leaves': 8, 'reg_alpha': 0, 'reg_lambda': 5.753371334200852, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001717 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001729 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001708 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9345421234189312, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8068582533507176, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008103675939961861, 'min_child_samples': 8, 'num_leaves': 4, 'reg_alpha': 7, 'reg_lambda': 6.906807500338849, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001841 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002391 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001903 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9265892002944951, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.9001211936986389, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009804755335275502, 'min_child_samples': 16, 'num_leaves': 14, 'reg_alpha': 3, 'reg_lambda': 5.818835217409236, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001472 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001478 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.003023 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8445862478281001, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9731169979832606, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.003931052130577687, 'min_child_samples': 24, 'num_leaves': 22, 'reg_alpha': 5, 'reg_lambda': 8.654929010126853, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001640 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001909 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001406 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9973874425515435, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8533024226123617, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006526227146288963, 'min_child_samples': 6, 'num_leaves': 42, 'reg_alpha': 0, 'reg_lambda': 4.128716187180639, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002000 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001636 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002024 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9905141307682112, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.8527239770757112, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0076988563697583815, 'min_child_samples': 6, 'num_leaves': 42, 'reg_alpha': 6, 'reg_lambda': 3.797049710420987, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001686 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001785 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002070 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9118953111144468, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.800958753572146, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009964508329040101, 'min_child_samples': 6, 'num_leaves': 42, 'reg_alpha': 0, 'reg_lambda': 4.133242420844492, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001639 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001667 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001770 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9972634732046035, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.7962920944726887, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.00925421226221481, 'min_child_samples': 6, 'num_leaves': 42, 'reg_alpha': 0, 'reg_lambda': 4.09991108871597, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001640 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001722 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002047 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9099482039357238, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.7898554466221986, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008555179830867038, 'min_child_samples': 6, 'num_leaves': 42, 'reg_alpha': 3, 'reg_lambda': 4.34979517307068, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001321 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002221 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001691 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9714828575021847, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.8394618485354347, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.00963550792902905, 'min_child_samples': 6, 'num_leaves': 42, 'reg_alpha': 8, 'reg_lambda': 1.9336257182265908, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001819 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001936 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001580 secs. 1 sparse feature groups       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.8052574570747211, 'bagging_freq': 1, 'device': 'gpu', 'feature_fraction': 0.7356798119061208, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006603410409417481, 'min_child_samples': 18, 'num_leaves': 2, 'reg_alpha': 5, 'reg_lambda': 0.7244205889543482, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001573 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001862 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001688 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9047992945499421, 'bagging_freq': 2, 'device': 'gpu', 'feature_fraction': 0.7680524240730379, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009943940089535955, 'min_child_samples': 6, 'num_leaves': 34, 'reg_alpha': 7, 'reg_lambda': 5.267777467390036, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001682 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001719 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001656 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9601140643195499, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.861453893645842, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.00405772525770366, 'min_child_samples': 22, 'num_leaves': 46, 'reg_alpha': 2, 'reg_lambda': 2.471505648337948, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002145 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002216 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001861 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.520372792914645, 'bagging_freq': 9, 'device': 'gpu', 'feature_fraction': 0.9164949526718543, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005355719269787893, 'min_child_samples': 20, 'num_leaves': 42, 'reg_alpha': 0, 'reg_lambda': 3.8146846325971655, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001782 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001939 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001626 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8201079314456564, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.8210272139631465, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0088399135012641, 'min_child_samples': 2, 'num_leaves': 38, 'reg_alpha': 6, 'reg_lambda': 5.914757993312792, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001723 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001689 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001825 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9146680832225829, 'bagging_freq': 4, 'device': 'gpu', 'feature_fraction': 0.6873986955819742, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0021362002691395986, 'min_child_samples': 28, 'num_leaves': 6, 'reg_alpha': 0, 'reg_lambda': 4.511933851121553, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001579 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002045 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002204 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8669862889480392, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.7736390759876004, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.003609203233158496, 'min_child_samples': 26, 'num_leaves': 44, 'reg_alpha': 4, 'reg_lambda': 3.12687964326952, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001951 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001725 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001621 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7858353084653834, 'bagging_freq': 2, 'device': 'gpu', 'feature_fraction': 0.642501483095774, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004734798324845094, 'min_child_samples': 24, 'num_leaves': 20, 'reg_alpha': 8, 'reg_lambda': 2.2419959029644922, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001871 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001842 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001668 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9993833030103976, 'bagging_freq': 1, 'device': 'gpu', 'feature_fraction': 0.7468102682815804, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0074737225009982675, 'min_child_samples': 14, 'num_leaves': 16, 'reg_alpha': 9, 'reg_lambda': 1.6090431326031283, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001667 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001753 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001867 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.5744501640182333, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.7190181069248394, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009196689928557392, 'min_child_samples': 6, 'num_leaves': 24, 'reg_alpha': 2, 'reg_lambda': 1.065747402565647, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001795 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001846 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.713847108876591, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.9650896782319344, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007005094162817785, 'min_child_samples': 12, 'num_leaves': 12, 'reg_alpha': 1, 'reg_lambda': 5.238185327011567, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001641 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001815 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001794 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9431444387834633, 'bagging_freq': 9, 'device': 'gpu', 'feature_fraction': 0.5487095446111854, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.002735451817844243, 'min_child_samples': 6, 'num_leaves': 48, 'reg_alpha': 6, 'reg_lambda': 0.2018946522363203, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001784 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002748 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001367 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9751819046828173, 'bagging_freq': 4, 'device': 'gpu', 'feature_fraction': 0.6669178523935494, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0064074470459644355, 'min_child_samples': 10, 'num_leaves': 40, 'reg_alpha': 0, 'reg_lambda': 3.4629297290246366, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001548 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001701 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001644 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8953390959154605, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.8709220131977782, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0011820189125611724, 'min_child_samples': 20, 'num_leaves': 28, 'reg_alpha': 3, 'reg_lambda': 6.2089734184645655, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001709 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001741 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001630 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.545597951262349, 'bagging_freq': 6, 'device': 'gpu', 'feature_fraction': 0.7086433658584254, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004924785691643349, 'min_child_samples': 8, 'num_leaves': 14, 'reg_alpha': 9, 'reg_lambda': 4.765949440158135, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001789 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001775 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001449 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6673822346946141, 'bagging_freq': 2, 'device': 'gpu', 'feature_fraction': 0.8325127519923035, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0021138024799480775, 'min_child_samples': 18, 'num_leaves': 32, 'reg_alpha': 4, 'reg_lambda': 4.068224577864036, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001540 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001793 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001642 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8261283973921656, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.9385814137983585, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008617510805555183, 'min_child_samples': 2, 'num_leaves': 36, 'reg_alpha': 0, 'reg_lambda': 2.912220482662468, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001987 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001423 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6186219839633667, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.9777624909953303, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005472375142182447, 'min_child_samples': 2, 'num_leaves': 22, 'reg_alpha': 7, 'reg_lambda': 0.6749046045855951, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001854 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001736 secs. 1 sparse feature groups       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001834 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7370809657601365, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.9332445778384052, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.00841702009392672, 'min_child_samples': 2, 'num_leaves': 36, 'reg_alpha': 5, 'reg_lambda': 2.8001623519258234, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001709 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001480 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001991 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7796852325198377, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.9537620632484713, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0071986766441445565, 'min_child_samples': 2, 'num_leaves': 36, 'reg_alpha': 8, 'reg_lambda': 1.5548905464671323, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001774 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001784 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001947 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8240755691649705, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.9951009959966646, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008753463203640122, 'min_child_samples': 28, 'num_leaves': 36, 'reg_alpha': 1, 'reg_lambda': 3.128700911084586, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001609 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001793 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001621 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7112615469467457, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.9095007140985087, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007775136054393793, 'min_child_samples': 16, 'num_leaves': 26, 'reg_alpha': 0, 'reg_lambda': 2.4253522581979876, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001666 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001888 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002196 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8792616605091863, 'bagging_freq': 6, 'device': 'gpu', 'feature_fraction': 0.9354126750325911, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006822260059546431, 'min_child_samples': 22, 'num_leaves': 18, 'reg_alpha': 0, 'reg_lambda': 1.9442818151792491, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001480 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001737 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001912 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6529012356492616, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8786360888453703, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005616947720168565, 'min_child_samples': 14, 'num_leaves': 34, 'reg_alpha': 2, 'reg_lambda': 6.809058529829935, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001302 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001661 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001710 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7635086434502808, 'bagging_freq': 9, 'device': 'gpu', 'feature_fraction': 0.977897018262288, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009362934758832544, 'min_child_samples': 2, 'num_leaves': 8, 'reg_alpha': 9, 'reg_lambda': 4.916553421294573, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001666 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001420 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001955 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8241080763102413, 'bagging_freq': 4, 'device': 'gpu', 'feature_fraction': 0.7812889289597186, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004214626631510305, 'min_child_samples': 12, 'num_leaves': 2, 'reg_alpha': 0, 'reg_lambda': 5.537270108216356, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001708 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001958 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001483 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9257412374284519, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.8060583374828774, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009726252626804363, 'min_child_samples': 6, 'num_leaves': 42, 'reg_alpha': 0, 'reg_lambda': 3.7231311023625095, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001750 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001642 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001789 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8627667935919339, 'bagging_freq': 1, 'device': 'gpu', 'feature_fraction': 0.855746091321429, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006271174569639075, 'min_child_samples': 26, 'num_leaves': 38, 'reg_alpha': 0, 'reg_lambda': 4.300981644274088, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001732 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001713 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001947 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9538655921705665, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.7550896408136829, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007671514448345492, 'min_child_samples': 6, 'num_leaves': 30, 'reg_alpha': 0, 'reg_lambda': 3.34717221164776, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001699 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001984 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001779 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9811141935514212, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8254535158471408, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009023941951671601, 'min_child_samples': 24, 'num_leaves': 42, 'reg_alpha': 0, 'reg_lambda': 2.922349337212393, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001787 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001987 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001998 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8867656485263538, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.9046823799305902, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.00814360998565298, 'min_child_samples': 10, 'num_leaves': 6, 'reg_alpha': 3, 'reg_lambda': 5.053998291294521, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001800 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001753 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.003105 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8071214994014603, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.8457539196096239, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009972781337213101, 'min_child_samples': 8, 'num_leaves': 10, 'reg_alpha': 0, 'reg_lambda': 4.080403463654978, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001745 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001841 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001619 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7448768378294659, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8026916484439208, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0067037501541101245, 'min_child_samples': 2, 'num_leaves': 44, 'reg_alpha': 6, 'reg_lambda': 1.1500582452409485, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001428 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001807 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001785 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9200299321463097, 'bagging_freq': 2, 'device': 'gpu', 'feature_fraction': 0.8864056755520628, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008572041112679254, 'min_child_samples': 6, 'num_leaves': 46, 'reg_alpha': 4, 'reg_lambda': 4.536503899662267, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002305 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002570 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002130 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8994127313325223, 'bagging_freq': 6, 'device': 'gpu', 'feature_fraction': 0.6092213061744832, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.009511932752148422, 'min_child_samples': 16, 'num_leaves': 36, 'reg_alpha': 7, 'reg_lambda': 6.234616184392612, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002446 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001754 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002433 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8586659081229262, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.7336849896188287, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007511856801340819, 'min_child_samples': 18, 'num_leaves': 12, 'reg_alpha': 5, 'reg_lambda': 2.6538616651522027, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002386 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002457 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001947 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8360348601181739, 'bagging_freq': 1, 'device': 'gpu', 'feature_fraction': 0.9520604948761604, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006208851157227623, 'min_child_samples': 22, 'num_leaves': 16, 'reg_alpha': 0, 'reg_lambda': 5.575268224352202, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002467 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002974 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002369 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9438313476481375, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8662528584607013, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007231944159734711, 'min_child_samples': 28, 'num_leaves': 20, 'reg_alpha': 1, 'reg_lambda': 2.2113670189154306, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002392 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002890 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002125 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7901346728604148, 'bagging_freq': 9, 'device': 'gpu', 'feature_fraction': 0.6758025387768263, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.007919446644121841, 'min_child_samples': 6, 'num_leaves': 42, 'reg_alpha': 8, 'reg_lambda': 3.6665118235950165, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002433 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.006686 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002084 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8692112793216747, 'bagging_freq': 4, 'device': 'gpu', 'feature_fraction': 0.9219973222285741, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005090552960808138, 'min_child_samples': 26, 'num_leaves': 24, 'reg_alpha': 0, 'reg_lambda': 3.0595322198154546, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001790 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002102 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001880 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.970090523281115, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.8155121317101933, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008683022413617228, 'min_child_samples': 20, 'num_leaves': 48, 'reg_alpha': 0, 'reg_lambda': 1.7100040867702093, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002339 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002698 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002498 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9368672544272278, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.8810134745865158, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0034110884389692278, 'min_child_samples': 14, 'num_leaves': 40, 'reg_alpha': 2, 'reg_lambda': 5.0666663181504195, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002612 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002120 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002093 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9576285848839173, 'bagging_freq': 8, 'device': 'gpu', 'feature_fraction': 0.7544447384738835, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008977440473280354, 'min_child_samples': 12, 'num_leaves': 42, 'reg_alpha': 3, 'reg_lambda': 3.9461106952542764, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001762 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002123 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001489 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.995593885420663, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9357568001545761, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005736982563398524, 'min_child_samples': 6, 'num_leaves': 28, 'reg_alpha': 0, 'reg_lambda': 7.279760155687339, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002336 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001768 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002379 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9950226703178666, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9866961216331575, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004763916712748397, 'min_child_samples': 24, 'num_leaves': 28, 'reg_alpha': 6, 'reg_lambda': 9.040223410111974, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002838 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002323 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002062 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7004613055747776, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9643954152477591, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005737127593896258, 'min_child_samples': 2, 'num_leaves': 28, 'reg_alpha': 4, 'reg_lambda': 6.9878613056259145, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001747 secs. 1 sparse feature groups       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.003603 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002352 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6825671710665467, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.936681879204089, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004404916141009189, 'min_child_samples': 6, 'num_leaves': 28, 'reg_alpha': 9, 'reg_lambda': 9.959495896864555, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001498 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001936 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002020 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7269996061137692, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8999351952245287, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005959387358524699, 'min_child_samples': 10, 'num_leaves': 32, 'reg_alpha': 7, 'reg_lambda': 7.919778958673239, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001994 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002411 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001965 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.598522719739598, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9117961223712437, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0037496501243542016, 'min_child_samples': 8, 'num_leaves': 26, 'reg_alpha': 5, 'reg_lambda': 7.5129548165190325, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002806 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.003732 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9826461010090319, 'bagging_freq': 2, 'device': 'gpu', 'feature_fraction': 0.9994407229665165, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005266260275751211, 'min_child_samples': 18, 'num_leaves': 14, 'reg_alpha': 0, 'reg_lambda': 8.96183767959606, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002180 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002749 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002109 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.5647660130494787, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9619544267284152, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006956412720639219, 'min_child_samples': 20, 'num_leaves': 22, 'reg_alpha': 1, 'reg_lambda': 9.676830822343575, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002704 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001964 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002092 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.5015182304431369, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.9864647355221153, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006383732439083359, 'min_child_samples': 6, 'num_leaves': 4, 'reg_alpha': 0, 'reg_lambda': 6.141895306095964, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002813 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001824 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002087 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.7735811338666884, 'bagging_freq': 6, 'device': 'gpu', 'feature_fraction': 0.785619731915005, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.005502975061834969, 'min_child_samples': 4, 'num_leaves': 18, 'reg_alpha': 8, 'reg_lambda': 8.482521400302394, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001985 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001879 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002236 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.661351932109291, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.9406529466149126, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0030435985920746777, 'min_child_samples': 16, 'num_leaves': 8, 'reg_alpha': 2, 'reg_lambda': 0.4696465072723779, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002602 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002200 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002537 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.6370571907680772, 'bagging_freq': 1, 'device': 'gpu', 'feature_fraction': 0.9259654840405188, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.008283222267133475, 'min_child_samples': 2, 'num_leaves': 36, 'reg_alpha': 0, 'reg_lambda': 7.11693573740957, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001738 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001913 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001956 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8131713541397244, 'bagging_freq': 9, 'device': 'gpu', 'feature_fraction': 0.8309929806832523, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.00493700207759724, 'min_child_samples': 28, 'num_leaves': 34, 'reg_alpha': 6, 'reg_lambda': 6.4220939211189085, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001950 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002229 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001899 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8335173671193481, 'bagging_freq': 4, 'device': 'gpu', 'feature_fraction': 0.8537287020262638, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.006641805747389036, 'min_child_samples': 22, 'num_leaves': 28, 'reg_alpha': 0, 'reg_lambda': 6.624916107105971, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001496 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002025 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002269 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.8808968109197503, 'bagging_freq': 7, 'device': 'gpu', 'feature_fraction': 0.8947751017913849, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004586462633181086, 'min_child_samples': 14, 'num_leaves': 38, 'reg_alpha': 9, 'reg_lambda': 7.448884731260755, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001495 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002798 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002602 secs. 1 sparse feature groups       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.8486671084359679, 'bagging_freq': 3, 'device': 'gpu', 'feature_fraction': 0.8747448934599309, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.002664927299120431, 'min_child_samples': 6, 'num_leaves': 2, 'reg_alpha': 4, 'reg_lambda': 5.934863477040347, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002300 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001845 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002319 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.9330947481750325, 'bagging_freq': 5, 'device': 'gpu', 'feature_fraction': 0.8473182177410429, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.0016489427603994444, 'min_child_samples': 26, 'num_leaves': 10, 'reg_alpha': 3, 'reg_lambda': 4.662927371183927, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002318 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002339 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001981 secs. 1 sparse feature groups       \n",
      "{'bagging_fraction': 0.5206925278517831, 'bagging_freq': 2, 'device': 'gpu', 'feature_fraction': 0.5249422199918682, 'gpu_device_id': 1, 'gpu_platform_id': 1, 'learning_rate': 0.004076959261800491, 'min_child_samples': 12, 'num_leaves': 30, 'reg_alpha': 7, 'reg_lambda': 0.006148153993370542, 'objective': ('regression',), 'metric': ('rmse',), 'feature_pre_filter': False}\n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002240 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.002141 secs. 1 sparse feature groups       \n",
      "[LightGBM] [Info] This is the GPU trainer!!                                                                            \n",
      "[LightGBM] [Info] Total Bins 116                                                                                       \n",
      "[LightGBM] [Info] Number of data points in the train set: 14, number of used features: 47                              \n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation                     \n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...                                                              \n",
      "[LightGBM] [Info] GPU programs have been built                                                                         \n",
      "[LightGBM] [Info] Size of histogram bin entry: 8                                                                       \n",
      "[LightGBM] [Info] 16 dense feature groups (0.00 MB) transferred to GPU in 0.001511 secs. 1 sparse feature groups       \n",
      "100%|██████████████████████████████████████████████| 100/100 [01:10<00:00,  1.41trial/s, best loss: 0.7066681791099277]\n"
     ]
    }
   ],
   "source": [
    "params = param_hyperopt(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11142dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:38:27.161612Z",
     "start_time": "2022-03-10T08:38:27.136624Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_predict(train,test,params):\n",
    "    label = 'TumorOrNormal'\n",
    "    features = [f for f in train.columns if f not in ['TumorOrNormal']]\n",
    "    params = params_append(params)\n",
    "    kf = sk.model_selection.KFold(n_splits=5,random_state=2020,shuffle=True)\n",
    "    prediction_test = 0\n",
    "    cv_score = []\n",
    "    prediction_train = pd.Series()\n",
    "    ESR = 30\n",
    "    NBR = 10000\n",
    "    VBE = 50\n",
    "    for train_part_index,eval_index in kf.split(train[features],train[label]):\n",
    "        train_part = lgb.Dataset(train[features].loc[train_part_index],train[label].loc[train_part_index])\n",
    "        eval = lgb.Dataset(train[features].loc[eval_index],train[label].loc[eval_index])\n",
    "        bst = lgb.train(params,train_part,num_boost_round=NBR,valid_sets=[train_part,eval],\n",
    "                        valid_names=['train','valid'],early_stopping_rounds=ESR,verbose_eval=VBE)\n",
    "        prediction_test += bst.predict(test[features])\n",
    "        prediction_train = prediction_train.append(pd.Series(\n",
    "        bst.predict(train[features].loc[eval_index]), index=eval_index))\n",
    "        eval_pre = bst.predict(train[features].loc[eval_index])\n",
    "        score = np.sqrt(sk.metrics.mean_absolute_error(train[label].loc[eval_index].values,eval_pre))\n",
    "        cv_score.append(score)\n",
    "        print(cv_score,sum(cv_score))\n",
    "        pd.Series(prediction_train.sort_index().values).to_csv(\n",
    "        \"../../Desktop/com result/train_lightgbm.csv\",index = False)\n",
    "        pd.Series(prediction_test).to_csv(\"../../Desktop/com result/test_lightgbm.csv\",index=False)\n",
    "        test['TumorOrNormal'] = prediction_test\n",
    "        test[['TumorOrNormal']].to_csv(\"../../Desktop/com result/submission_lightgbm.csv\",index=False)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f00bb40e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:39:06.527145Z",
     "start_time": "2022-03-10T08:39:06.500148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 788, number of negative: 81\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4306\n",
      "[LightGBM] [Info] Number of data points in the train set: 869, number of used features: 37\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.906789 -> initscore=2.275049\n",
      "[LightGBM] [Info] Start training from score 2.275049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttrain's auc: 0.996577\tvalid's auc: 0.996667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttrain's auc: 0.996702\tvalid's auc: 0.997778\n",
      "[0.3710052066339556] 0.3710052066339556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_1568\\3298179350.py:8: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  prediction_train = pd.Series()\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_1568\\3298179350.py:18: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(\n"
     ]
    }
   ],
   "source": [
    "train_predict(train,test,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6161bda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5545163222455658,\n",
       " 'bagging_freq': 2,\n",
       " 'feature_fraction': 0.7264507118399341,\n",
       " 'learning_rate': 0.027718553528183795,\n",
       " 'min_child_samples': 5,\n",
       " 'num_leaves': 132,\n",
       " 'reg_alpha': 7,\n",
       " 'reg_lambda': 3.2195131541752375}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params\n",
    "#LncRNA all loss:0.0009955399133204645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9194bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T11:34:44.803147Z",
     "start_time": "2022-01-18T11:34:44.794145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_part = lgb.Dataset(test)\n",
    "gbm_y_pre = pd.read_csv(filepath_or_buffer=\"../../Desktop/recent/testNew answer.csv\")\n",
    "gbm_y_proba = bst.predict(test[features]) # 分类的类别\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "gbm_auc = roc_auc_score(gbm_y_pre['x'], gbm_y_proba[:,])  # 计算auc\n",
    "gbm_fpr, gbm_tpr, gbm_threasholds = roc_curve(gbm_y_pre['x'], gbm_y_proba[:,])  # 计算ROC的值\n",
    "plt.title(\"roc_curve of %s(AUC=%.4f)\" % ('gbm', gbm_auc))\n",
    "plt.xlabel('Specificity')  # specificity = 1 - np.array(gbm_fpr))\n",
    "plt.ylabel('Sensitivity')  # sensitivity = gbm_tpr\n",
    "plt.plot(list(1 - np.array(gbm_fpr)), gbm_tpr)\n",
    "plt.gca().invert_xaxis()  # 将X轴反转\n",
    "plt.savefig(\"auc.jpg\",format = \"jpg\",bbox_inches = 'tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd7ad9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting split value histogram...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plotting split value histogram...')\n",
    "ax = lgb.plot_split_value_histogram(bst,feature='ADAMTS9-AS2', bins='auto')\n",
    "plt.savefig(\"training histogramTumorOrNormal_ADAMTS9-AS2.jpg\", format=\"jpg\",bbox_inches = 'tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c443aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 4th tree...\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\backend\\execute.py:79\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[1;32m---> 79\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43m_run_input_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\backend\\execute.py:99\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_input_lines\u001b[39m(cmd, input_lines, \u001b[38;5;241m*\u001b[39m, kwargs):\n\u001b[1;32m---> 99\u001b[0m     popen \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(cmd, stdin\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    101\u001b[0m     stdin_write \u001b[38;5;241m=\u001b[39m popen\u001b[38;5;241m.\u001b[39mstdin\u001b[38;5;241m.\u001b[39mwrite\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:969\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    967\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1438\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1438\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlotting 4th tree...\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# one tree use categorical feature to split\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msplit_gain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining tree.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\plotting.py:689\u001b[0m, in \u001b[0;36mplot_tree\u001b[1;34m(booster, ax, tree_index, figsize, dpi, show_info, precision, orientation, **kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m graph \u001b[38;5;241m=\u001b[39m create_tree_digraph(booster\u001b[38;5;241m=\u001b[39mbooster, tree_index\u001b[38;5;241m=\u001b[39mtree_index,\n\u001b[0;32m    685\u001b[0m                             show_info\u001b[38;5;241m=\u001b[39mshow_info, precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[0;32m    686\u001b[0m                             orientation\u001b[38;5;241m=\u001b[39morientation, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    688\u001b[0m s \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[1;32m--> 689\u001b[0m s\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    690\u001b[0m s\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    691\u001b[0m img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimread(s)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     56\u001b[0m          \u001b[38;5;28mformat\u001b[39m: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m          renderer: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m          engine: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     62\u001b[0m          encoding: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m        '<?xml version='\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_legacy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@_tools\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecate_positional_args(supported_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe_legacy\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    114\u001b[0m                  \u001b[38;5;28mformat\u001b[39m: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m                  engine: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    120\u001b[0m                  encoding: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\piping.py:161\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m raw\u001b[38;5;241m.\u001b[39mdecode(encoding)\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_lines(\u001b[38;5;241m*\u001b[39margs, input_encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\backend\\piping.py:161\u001b[0m, in \u001b[0;36mpipe_lines\u001b[1;34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    155\u001b[0m cmd \u001b[38;5;241m=\u001b[39m dot_command\u001b[38;5;241m.\u001b[39mcommand(engine, \u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    156\u001b[0m                           renderer\u001b[38;5;241m=\u001b[39mrenderer,\n\u001b[0;32m    157\u001b[0m                           formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[0;32m    158\u001b[0m                           neato_no_op\u001b[38;5;241m=\u001b[39mneato_no_op)\n\u001b[0;32m    159\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_lines\u001b[39m\u001b[38;5;124m'\u001b[39m: (line\u001b[38;5;241m.\u001b[39mencode(input_encoding) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m input_lines)}\n\u001b[1;32m--> 161\u001b[0m proc \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mrun_check(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, quiet\u001b[38;5;241m=\u001b[39mquiet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\backend\\execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[1;32m---> 84\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plotting 4th tree...')  # one tree use categorical feature to split\n",
    "ax = lgb.plot_tree(bst, tree_index=4, figsize=(15, 15), show_info=['split_gain'])\n",
    "plt.savefig(\"training tree.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe66ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.5508139325442933,\n",
    " 'bagging_freq': 1,\n",
    " 'feature_fraction': 0.8719686448263485,\n",
    " 'learning_rate': 0.006743668710798017,\n",
    " 'min_child_samples': 2,\n",
    " 'num_leaves': 17,\n",
    " 'reg_alpha': 0,\n",
    " 'reg_lambda': 7.304874591640652}\n",
    "#lncRNA all immune loss: 0.04611817398018202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afb6943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.8566159041991672,\n",
    " 'bagging_freq': 5,\n",
    " 'feature_fraction': 0.6902047188337582,\n",
    " 'learning_rate': 0.009462027923488296,\n",
    " 'min_child_samples': 0,\n",
    " 'num_leaves': 2,\n",
    " 'reg_alpha': 1,\n",
    " 'reg_lambda': 0.3608321566845435,\n",
    " 'objective': ('regression',),\n",
    " 'metric': ('rmse',),\n",
    " 'feature_pre_filter': False}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.854px",
    "left": "909px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
